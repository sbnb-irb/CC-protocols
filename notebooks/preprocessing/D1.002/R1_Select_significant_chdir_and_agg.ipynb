{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FIRST, RUN chbir_bing_cp.py & run_chdir.py\n",
    "### THEN, RUN THIS NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "import h5py\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import spearmanr as scor\n",
    "from scipy.spatial.distance import pdist, cosine, euclidean\n",
    "from scipy.stats import gaussian_kde\n",
    "from random import sample \n",
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to metadata and to the dict created (run_chdir.py)\n",
    "root_LINCS = '/aloy/home/epareja/TFM/Data/LINCS/2020_data/levelIII/' \n",
    "# Path to the Chdir results (one per batch)\n",
    "root_out = '/slgpfs/projects/irb35/epareja/LINCS_2020/chdir_result/'\n",
    "# Path to the metadata\n",
    "root_LINCS_meta = '/aloy/home/epareja/TFM/Data/LINCS/2020_data/metadata/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Select signatures that fulfill the concordance of the replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batches = set([('_').join(i.split('_')[0:3]) for i in os.listdir(root_out) if i.endswith('_chdir.h5')]) # Get the batches\n",
    "sig2inst = pickle.load(open(root_LINCS + 'CP_sig_id2distil_ids.p', 'rb')) # Load the dict relating the sig_id and the inst_id\n",
    "\n",
    "def obtain_significant_sig (filter_val): \n",
    "    '''\n",
    "    Function for obtaining a list with the sig_id of the GEx signatures that pass the filter\n",
    "    filter val --> 2 for 0.05 and 3 for 0.10\n",
    "    \n",
    "    '''\n",
    "    significant_sig = [] \n",
    "\n",
    "    for i in tqdm(batches): \n",
    "        # Load sig order and pval of all the calculated CD signatures of the current batch\n",
    "        with h5py.File(root_out + i + '_chdir.h5', \"r\") as hf: \n",
    "            sig_ids = hf['ids'][:].astype('str')\n",
    "            cos_pval = hf['cos_pval'][:]\n",
    "            rep = hf['rep'][:]\n",
    "\n",
    "        # Load filtering matrix: cutoff order, number of replicates order and threshold\n",
    "        with h5py.File(root_out + i + '_bck_cutoffs.h5', \"r\") as hf: \n",
    "            cutoff = hf['cutoffs'][:]\n",
    "            replicates = hf['replicates'][:]\n",
    "            values = hf['values'][:]\n",
    "\n",
    "        if replicates.shape[0] == 1: \n",
    "            idx_sig = np.where(cos_pval< values[0][filter_val]) # which sig pass the 0.10 or 0.05 filter\n",
    "            significant_sig.append(sig_ids[idx_sig])\n",
    "\n",
    "        else:\n",
    "            for sig in range(len(sig_ids)):\n",
    "                current_num = np.array(rep)[sig]\n",
    "                idx_cutoff = np.where(replicates == current_num)[0][0]\n",
    "                current_cutoff = values[idx_cutoff][filter_val]\n",
    "                if cos_pval[sig] < current_cutoff:\n",
    "                    significant_sig.append(sig_ids[sig])   \n",
    "\n",
    "    sig_pass = []\n",
    "    for i in tqdm(np.array(significant_sig)): \n",
    "        if type(i) == np.ndarray: \n",
    "            for sig in i: \n",
    "                sig_pass.append(sig)\n",
    "        else:\n",
    "            sig_pass.append(i)\n",
    "\n",
    "    return(sig_pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_pass_10 = obtain_significant_sig(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_info = pd.read_csv(root_LINCS_meta + \"siginfo_beta.txt\", sep = \"\\t\", dtype=str).set_index('sig_id')\n",
    "sig_info.reset_index(inplace = True)\n",
    "sig_info_10 = sig_info[sig_info.sig_id.isin(sig_pass_10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_preprocess = '/aloy/home/epareja/TFM/Script/LINCS/4_LINCS_2020/preprocess_result/'\n",
    "\n",
    "with h5py.File(root_preprocess + 'id_significative.h5', \"w\") as o:\n",
    "    o.create_dataset('ids_10', data = np.array(sig_info_10.sig_id, dtype = 'S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Add chdir from all significant samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(root_preprocess + 'id_significative.h5', \"r\") as o:\n",
    "    ids_10 = o['ids_10'][:].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_info = pd.read_csv(\"/aloy/home/epareja/TFM/Data/LINCS/2020_data/metadata/siginfo_beta.txt\", sep = \"\\t\")\n",
    "cp_info = pd.read_csv('/aloy/home/epareja/TFM/Data/LINCS/2020_data/metadata/cp_info_inchikey_standard.txt', sep = '\\t', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_info = sig_info[sig_info.sig_id.isin(ids_10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.array(sig_info['sig_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_10 = set([i.split(':')[0] for i in ids])\n",
    "\n",
    "chdir = []\n",
    "sig_order = []\n",
    "\n",
    "for i in tqdm(batches_10): \n",
    "        # Load sig order and pval of all the calculated CD signatures of the current batch\n",
    "        f=np.frompyfunc(lambda x: i in x,1,1)\n",
    "        ids_batch = ids[np.where(f(ids))]\n",
    "        \n",
    "        with h5py.File(root_out + i + '_chdir.h5', \"r\") as hf: \n",
    "            sig_ids = hf['ids'][:].astype('str')\n",
    "            idx = [np.where(sig_ids == i)[0][0] for i in ids_batch]\n",
    "            idx.sort()\n",
    "            sig_order.append(sig_ids[idx])\n",
    "            chdir.append(hf['chdir'][np.array(idx)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_order = np.concatenate(np.array(sig_order).flatten())\n",
    "chdir = np.concatenate(np.array(chdir).flatten())\n",
    "\n",
    "with h5py.File('chdir_active_no_agg.h5', \"w\") as o:\n",
    "    o.create_dataset('sig_id', data = np.array(sig_order, dtype = 'S'))\n",
    "    o.create_dataset('chdir', data = np.array(chdir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Aggregate (using MODZ) the chdir values of the same compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_info = cp_info[cp_info.pert_id.isin(sig_info.pert_id.unique())][['pert_id', 'inchikey_standard']]\n",
    "cp_info = cp_info.drop_duplicates()\n",
    "sig_info = sig_info.set_index('pert_id').merge(cp_info.set_index('pert_id')['inchikey_standard'], right_index=True, left_index=True)\n",
    "sig_info.reset_index(inplace = True)\n",
    "drugs = sig_info.inchikey_standard.unique()\n",
    "sig_info = sig_info.set_index('inchikey_standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_MODZ(data):\n",
    "    \"\"\"calculates MODZ based on the original CMAP/L1000 study\"\"\"\n",
    "    if len(data)==1:\n",
    "        return data.flatten()\n",
    "    if len(data)==2:\n",
    "        return np.mean(data,0)\n",
    "    else:\n",
    "        CM=scor(data.T)[0]\n",
    "        fil=CM<0\n",
    "        CM[fil]=0.01\n",
    "        weights=np.sum(CM,1)-1\n",
    "        weights=weights/np.sum(weights)\n",
    "        weights=weights.reshape((-1,1))\n",
    "        return np.dot(data.T,weights).reshape((-1,1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop that go to all the drugs and save the different signatures \n",
    "# with this signatures produce a consensus signatures using the modz\n",
    "\n",
    "consensus = []\n",
    "order_drugs = []\n",
    "\n",
    "for dg in tqdm(drugs): \n",
    "    \n",
    "    if len(pd.Series(sig_info.loc[dg]['sig_id'])) == 1: \n",
    "        idx_sig = np.where(sig_order == sig_info.loc[dg]['sig_id'])\n",
    "        chdir_current = chdir[idx_sig]\n",
    "        a = calc_MODZ(chdir_current)\n",
    "        consensus.append(a)\n",
    "        order_drugs.append(dg)\n",
    "\n",
    "    else: \n",
    "\n",
    "        sig_id_list = sig_info.loc[dg]['sig_id']\n",
    "        idx_sig = [np.where(sig_order == i)[0] for i in sig_id_list]\n",
    "        idx_sig = np.concatenate(idx_sig)\n",
    "        chdir_current = chdir[idx_sig]\n",
    "        a = calc_MODZ(chdir_current)\n",
    "        consensus.append(a)\n",
    "        order_drugs.append(dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_preprocess = '/aloy/home/epareja/TFM/Script/LINCS/4_LINCS_2020/preprocess_result/'\n",
    "\n",
    "with h5py.File(root_preprocess + 'chdir_active_10.h5', \"w\") as o:\n",
    "    o.create_dataset('keys', data = np.array(order_drugs, dtype = 'S'))\n",
    "    o.create_dataset('V', data = np.array(consensus))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
